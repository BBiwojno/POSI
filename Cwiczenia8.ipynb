{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BBiwojno/POSI/blob/main/Cwiczenia8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ćwiczenia 8"
      ],
      "metadata": {
        "id": "j8ER7gHzAgTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wprowadzenie"
      ],
      "metadata": {
        "id": "CNy2ld8r2uwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jak działa KNN?\n",
        "\n",
        "Algorytm KNN działa na zasadzie porównywania nowych danych z danymi już znanymi (tzw. treningowymi). Jego główną ideą jest to, że obiekty, które są \"blisko siebie\" (tzn. mają podobne cechy), są bardziej podobne do siebie i powinny być klasyfikowane w ten sam sposób. Działa to na zasadzie:\n",
        "\n",
        "1. **Określenie liczby sąsiadów (K)** – użytkownik wybiera liczbę $ K $, czyli ile najbliższych sąsiadów należy brać pod uwagę przy klasyfikacji.\n",
        "2. **Obliczanie odległości** – dla danego punktu (np. nowego przykładu, który chcemy sklasyfikować) algorytm oblicza odległość do wszystkich innych punktów w zbiorze treningowym (zwykle stosuje się metrykę Euklidesową, ale mogą to być inne odległości, jak Manhattan).\n",
        "3. **Wybór K najbliższych sąsiadów** – algorytm wybiera $ K $ punktów z treningowego zbioru danych, które są najbliższe do punktu, który chcemy sklasyfikować.\n",
        "4. **Klasyfikacja/średnia** – na podstawie klasy (dla klasyfikacji) lub wartości (dla regresji) $ K $ najbliższych sąsiadów, algorytm przypisuje etykietę nowemu punktowi. W przypadku klasyfikacji będzie to najczęściej najczęstsza klasa spośród $ K $ sąsiadów, a w przypadku regresji – średnia wartość.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Przykład:\n",
        "\n",
        "Załóżmy, że masz zbiór danych o kwiatach, z dwoma cechami: długość i szerokość płatków. Chcesz sklasyfikować nowy kwiat. Algorytm KNN znajdzie $ K $ najbardziej podobnych kwiatów w zbiorze treningowym (np. 5 najbliższych) i przypisze nowemu kwiatowi etykietę na podstawie większości (np. \"iris-setosa\", jeśli 3 z 5 najbliższych są setosą).\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Zalety i wady:\n",
        "\n",
        "##### Zalety:\n",
        "- Prosty do zrozumienia i implementacji.\n",
        "- Nie wymaga treningu modelu, działa \"na bieżąco\".\n",
        "- Może być używany do wielu typów danych (np. klasyfikacja, regresja).\n",
        "\n",
        "##### Wady:\n",
        "- **Wydajność obliczeniowa**: im większy zbiór danych, tym więcej operacji.\n",
        "- **Wrażliwość na szum i nieistotne cechy.**\n",
        "- Wymaga odpowiedniej metryki odległości (choć w niektórych przypadkach może być trudne do wyboru).\n"
      ],
      "metadata": {
        "id": "WhehbpCa_FNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Miary odległości\n",
        "\n",
        "#### 1. Odległość Euklidesowa (Euclidean Distance)\n",
        "\n",
        "Jest to najbardziej powszechnie stosowana metryka, szczególnie w klasycznych zadaniach klasyfikacji i regresji, gdy dane są ciągłe.\n",
        "\n",
        "##### Wzór:\n",
        "\n",
        "$$\n",
        "d_E = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + \\dots + (x_n - y_n)^2}\n",
        "$$\n",
        "\n",
        "Gdzie:\n",
        "\n",
        "- $ x_1, x_2, \\dots, x_n $ to współrzędne punktu $ x $,\n",
        "- $ y_1, y_2, \\dots, y_n $ to współrzędne punktu $ y $,\n",
        "- $ n $ to liczba wymiarów (cech).\n",
        "\n",
        "##### Przykład:\n",
        "\n",
        "Jeśli mamy dwa punkty w 2 wymiarach: $ x = (3, 4) $ i $ y = (7, 1) $, to odległość Euklidesowa między nimi to:\n",
        "\n",
        "$$\n",
        "d_E = \\sqrt{(3 - 7)^2 + (4 - 1)^2} = \\sqrt{(-4)^2 + 3^2} = \\sqrt{16 + 9} = \\sqrt{25} = 5\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 2. Odległość Manhattan (Manhattan Distance)\n",
        "\n",
        "Jest to alternatywna miara, która sumuje różnice współrzędnych punktów wzdłuż osi. Jest szczególnie użyteczna, gdy dane są zorganizowane w siatkę (np. w przypadku problemów związanych z ruchem w miastach).\n",
        "\n",
        "##### Wzór:\n",
        "\n",
        "$$\n",
        "d_M = |x_1 - y_1| + |x_2 - y_2| + \\dots + |x_n - y_n|\n",
        "$$\n",
        "\n",
        "##### Przykład:\n",
        "\n",
        "Dla punktów $ x = (3, 4) $ i $ y = (7, 1) $, odległość Manhattan to:\n",
        "\n",
        "$$\n",
        "d_M = |3 - 7| + |4 - 1| = 4 + 3 = 7\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 3. Odległość Minkowskiego (Minkowski Distance)\n",
        "\n",
        "Jest ogólną formą obu powyższych metryk. Odległość Minkowskiego może przyjąć różne wartości w zależności od parametru $ p $.\n",
        "\n",
        "##### Wzór:\n",
        "\n",
        "$$\n",
        "d_M = \\left( |x_1 - y_1|^p + |x_2 - y_2|^p + \\dots + |x_n - y_n|^p \\right)^{1/p}\n",
        "$$\n",
        "\n",
        "Gdy $ p = 1 $, odległość Minkowskiego jest równa odległości Manhattan.\n",
        "\n",
        "Gdy $ p = 2 $, jest to odległość Euklidesowa.\n",
        "\n",
        "##### Przykład:\n",
        "\n",
        "Dla punktów $ x = (3, 4) $ i $ y = (7, 1) $, jeśli $ p = 3 $:\n",
        "\n",
        "$$\n",
        "d_M = \\left( |3 - 7|^3 + |4 - 1|^3 \\right)^{1/3} = \\left( 4^3 + 3^3 \\right)^{1/3} = \\left( 64 + 27 \\right)^{1/3} = 91^{1/3} \\approx 4.5\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Podsumowanie\n",
        "\n",
        "W zależności od charakterystyki danych i problemu, możesz wybierać odpowiednią metrykę odległości:\n",
        "\n",
        "- **Euklidesowa** – najczęściej stosowana w zadaniach ogólnych (ciągłe dane).\n",
        "- **Manhattan** – dla danych, które dobrze opisują \"ruch\" w siatce.\n",
        "- **Minkowski** – ogólna forma, pozwalająca na eksperymentowanie z parametrem $ p $.\n"
      ],
      "metadata": {
        "id": "d_ut8hYYuI6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zadanie 1\n",
        "Dla zbioru danych `load_wine` z modułu `sklearn.datasets` przeprowadź analizę DEA oraz klasyfikację cechy `target` z wykorzystaniem `KNN`. Sprawdź diałanie modelu dla różnych wartości `k-sąsiadów`. Pamiętaj o skalowaniu danych.\n",
        "\n",
        "<br>\n",
        "\n",
        "Przykład ładowania danych:\n",
        "\n",
        "```\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine = load_wine()\n",
        "\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "```"
      ],
      "metadata": {
        "id": "LtPGz00R2hsq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0rl2zI1PnLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5264abb4",
        "outputId": "4fb2f1c5-00c2-4107-b66f-d251e1597fa4"
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (142, 13)\n",
            "Shape of X_test: (36, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcff1c2b",
        "outputId": "dbfcd686-6163-4ac7-d5c5-3cbf71793548"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "print(\"buh skalowanie .\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features scaled successfully for both training and testing sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "681880f1",
        "outputId": "d5562b94-d80e-475d-9358-21deba07226b"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "k_values = range(1, 21)  # 1-20\n",
        "accuracies = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "    y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"k = {k}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "best_k_index = np.argmax(accuracies)\n",
        "best_k = k_values[best_k_index]\n",
        "best_accuracy = accuracies[best_k_index]\n",
        "\n",
        "print(f\"\\nBest k value: {best_k} with Accuracy: {best_accuracy:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k = 1, Accuracy: 0.9444\n",
            "k = 2, Accuracy: 0.9444\n",
            "k = 3, Accuracy: 0.9444\n",
            "k = 4, Accuracy: 0.9444\n",
            "k = 5, Accuracy: 0.9444\n",
            "k = 6, Accuracy: 0.9444\n",
            "k = 7, Accuracy: 0.9444\n",
            "k = 8, Accuracy: 0.9722\n",
            "k = 9, Accuracy: 0.9444\n",
            "k = 10, Accuracy: 0.9722\n",
            "k = 11, Accuracy: 0.9444\n",
            "k = 12, Accuracy: 0.9722\n",
            "k = 13, Accuracy: 0.9722\n",
            "k = 14, Accuracy: 0.9722\n",
            "k = 15, Accuracy: 0.9722\n",
            "k = 16, Accuracy: 0.9722\n",
            "k = 17, Accuracy: 0.9722\n",
            "k = 18, Accuracy: 0.9722\n",
            "k = 19, Accuracy: 0.9444\n",
            "k = 20, Accuracy: 0.9722\n",
            "\n",
            "Best k value: 8 with Accuracy: 0.9722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a8546e6"
      },
      "source": [
        "Kluczowe wnioski z analizy danych\n",
        "\n",
        "Zestaw danych wine został pomyślnie załadowany i podzielony na zbiór treningowy i testowy. Zbiór treningowy (X_train) zawierał 142 próbki z 13 cechami, podczas gdy zbiór testowy (X_test) zawierał 36 próbek z 13 cechami.\n",
        "\n",
        "Skalowanie cech zostało przeprowadzone przy użyciu StandardScaler zarówno na danych treningowych, jak i testowych, co jest istotne dla algorytmów opartych na odległości, takich jak K-Nearest Neighbors (KNN).\n",
        "\n",
        "Model K-Nearest Neighbors (KNN) został oceniony dla wartości k w zakresie od 1 do 20.\n",
        "\n",
        "Najwyższa dokładność klasyfikacji osiągnięta na zbiorze testowym wyniosła około 0.9722 (97,22%).\n",
        "\n",
        "Ta maksymalna dokładność została osiągnięta dla wielu wartości k, w tym 8, 10, 12, 13, 14, 15, 16, 17, 18 i 20. Pierwszą wartością k, która osiągnęła tę maksymalną dokładność, było k=8.\n",
        "\n",
        "Wnioski lub kolejne kroki\n",
        "\n",
        "Wysoka osiągnięta dokładność (97,22%) sugeruje, że KNN, po przeprowadzeniu skalowania cech, jest bardzo skutecznym klasyfikatorem dla zestawu danych wine.\n",
        "\n",
        "Dalsze badania mogą obejmować ocenę innych metryk klasyfikacji (np. precyzji, czułości, F1-score) lub porównanie wydajności KNN z innymi algorytmami klasyfikacyjnymi, aby potwierdzić jego przydatność."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zadanie 2\n",
        "Dla zbioru danych `fetch_california_housing` z modułu `sklearn.datasets` przeprowadź analizę DEA oraz regresję z wykorzystaniem `KNN`. Sprawdź diałanie modelu dla różnych wartości `k-sąsiadów`. Pamiętaj o skalowaniu danych.\n",
        "\n",
        "<br>\n",
        "\n",
        "Przykład ładowania danych:\n",
        "\n",
        "```\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "```"
      ],
      "metadata": {
        "id": "ga00M6JV2Vqh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "166020ea",
        "outputId": "6d4bb953-0464-491b-f149-2e508746904c"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (16512, 8)\n",
            "Shape of X_test: (4128, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "878fc370",
        "outputId": "5240c345-c33e-4195-d5b8-c45ddcdcb634"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Skalowanie\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"buh skalowanie\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features scaled successfully for both training and testing sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bbb2dde"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to perform KNN regression using `KNeighborsRegressor`, evaluating its performance for different `k` values by calculating the Mean Squared Error (MSE).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "055e4396",
        "outputId": "5572eb48-7dd6-48a6-92d9-c2de7f11b98e"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "k_values = range(1, 21)  # 1-20\n",
        "mse_scores = []\n",
        "\n",
        "\n",
        "for k in k_values:\n",
        "    knn_regressor = KNeighborsRegressor(n_neighbors=k)\n",
        "\n",
        "    knn_regressor.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred = knn_regressor.predict(X_test_scaled)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "    print(f\"k = {k}, Mean Squared Error: {mse:.4f}\")\n",
        "\n",
        "best_k_index = np.argmin(mse_scores)\n",
        "best_k = k_values[best_k_index]\n",
        "best_mse = mse_scores[best_k_index]\n",
        "\n",
        "print(f\"\\nBest k value: {best_k} with Mean Squared Error: {best_mse:.4f}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k = 1, Mean Squared Error: 0.6690\n",
            "k = 2, Mean Squared Error: 0.5229\n",
            "k = 3, Mean Squared Error: 0.4667\n",
            "k = 4, Mean Squared Error: 0.4474\n",
            "k = 5, Mean Squared Error: 0.4324\n",
            "k = 6, Mean Squared Error: 0.4291\n",
            "k = 7, Mean Squared Error: 0.4283\n",
            "k = 8, Mean Squared Error: 0.4245\n",
            "k = 9, Mean Squared Error: 0.4246\n",
            "k = 10, Mean Squared Error: 0.4215\n",
            "k = 11, Mean Squared Error: 0.4186\n",
            "k = 12, Mean Squared Error: 0.4182\n",
            "k = 13, Mean Squared Error: 0.4163\n",
            "k = 14, Mean Squared Error: 0.4179\n",
            "k = 15, Mean Squared Error: 0.4188\n",
            "k = 16, Mean Squared Error: 0.4210\n",
            "k = 17, Mean Squared Error: 0.4211\n",
            "k = 18, Mean Squared Error: 0.4214\n",
            "k = 19, Mean Squared Error: 0.4218\n",
            "k = 20, Mean Squared Error: 0.4235\n",
            "\n",
            "Best k value: 13 with Mean Squared Error: 0.4163\n"
          ]
        }
      ]
    }
  ]
}